{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5zh1-LnZcSA"
      },
      "source": [
        "**Avant de débuter ce TP** :\n",
        "\n",
        "1. **Changez le type d'exécution sur Google Colab** : `Exécution > Modifiez le type d'exécution > T4 GPU`\n",
        "2. **Installez les paquets ci-dessous** :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "x6ry5k1YZcSB",
        "outputId": "7bcc31d5-3920-40a5-de79-5237fcb12a30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lightning\n",
            "  Downloading lightning-2.4.0-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.5.1-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.10/dist-packages (from lightning) (6.0.2)\n",
            "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (2024.6.1)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning)\n",
            "  Downloading lightning_utilities-0.11.8-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (24.1)\n",
            "Requirement already satisfied: torch<4.0,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (2.5.0+cu121)\n",
            "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.12.2)\n",
            "Collecting pytorch-lightning (from lightning)\n",
            "  Downloading pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: numpy<2.0,>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (3.10.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning) (75.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=2.1.0->lightning) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch<4.0,>=2.1.0->lightning) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.16.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<4.0,>=2.1.0->lightning) (3.0.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (3.10)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (0.2.0)\n",
            "Downloading lightning-2.4.0-py3-none-any.whl (810 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m811.0/811.0 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.5.1-py3-none-any.whl (890 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m890.6/890.6 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Downloading lightning_utilities-0.11.8-py3-none-any.whl (26 kB)\n",
            "Downloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchinfo, lightning-utilities, torchmetrics, pytorch-lightning, lightning\n",
            "Successfully installed lightning-2.4.0 lightning-utilities-0.11.8 pytorch-lightning-2.4.0 torchinfo-1.8.0 torchmetrics-1.5.1\n"
          ]
        }
      ],
      "source": [
        "! pip install lightning torchmetrics torchinfo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qctHFtPZcSC"
      },
      "source": [
        "3. Exécutez ce code pour supprimer quelques messages et avertissements éventuellement affichés."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbLvvDYMZcSD"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "logging.getLogger(\"lightning\").setLevel(logging.ERROR)\n",
        "logging.getLogger(\"lightning.pytorch.utilities.rank_zero\").setLevel(logging.WARNING)\n",
        "logging.getLogger(\"lightning.pytorch.accelerators.cuda\").setLevel(logging.WARNING)\n",
        "logger = logging.getLogger(\"lightning\")\n",
        "logger.propagate = False\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", \".*does not have many workers.*\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSC3mixZZcSD"
      },
      "source": [
        "# Identification d'activité humaine\n",
        "\n",
        "Dans ce notebook, vous allez travailler sur le jeu de données [Human Activity Recognition](https://archive.ics.uci.edu/dataset/240/human+activity+recognition+using+smartphones).\n",
        "\n",
        "Ce jeu de données a été construit à partir d'enregistrements de 30 sujets effectuant des activités de la vie quotidienne tout en portant un smartphone monté à la taille équipé de capteurs d'inertie.\n",
        "\n",
        "Voici quelques informations supplémentaires sur les expériences effectuées :\n",
        "\n",
        "> Les expériences ont été menées avec un groupe de 30 volontaires âgés de 19 à 48 ans. Chaque personne a effectué six activités (*marche*, *monter des marches*, *descendre des marches*, *assis*, *debout*, *couché*) en portant un smartphone (Samsung Galaxy S II) à la taille. En utilisant l'accéléromètre et le gyroscope intégrés, ils ont capturé l'accélération linéaire et la vitesse angulaire de trois axes à une fréquence constante de 50 Hz. Les expériences ont également été enregistrées avec une caméra afin d'étiqueter les données manuellement. L'ensemble des données obtenues a été divisé de manière aléatoire en deux ensembles, 70% des volontaires ayant été sélectionnés pour générer les données d'entraînement et 30% les données d'évaluation. Les signaux des capteurs (accéléromètre et gyroscope) ont été prétraités en appliquant des filtres anti-bruit, puis échantillonnés dans des fenêtres glissantes de largeur fixe de 2,56 secondes avec un chevauchement de 50% (128 valeurs par fenêtre).\n",
        "\n",
        "**L'objectif est de prédire l'activité effectuée par le sujet à partir des signaux enregistrés par le capteur puis prétraités.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYAPrgzLZcSD"
      },
      "source": [
        "## (Télé)chargement des données, visualisation et prétraitement\n",
        "\n",
        "La fonction `load_dataset()` définie ci-dessous permet de charger (et télécharger si nécessaire) le jeu de données."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHqOvVrcZcSE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "def load_dataset(train, path='data'):\n",
        "    \"\"\"Charge le jeu de données.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    train : bool\n",
        "        Si True, renvoie le jeu d'entraînement. Sinon, renvoie le\n",
        "        jeu de validation.\n",
        "\n",
        "    path : str\n",
        "        Chemin du répertoire où charger ou télécharger le jeu de données.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    X : Tensor, shape = (n_samples, 9, 128)\n",
        "        Entrées.\n",
        "\n",
        "    y : Tensor, shape = (n_samples,)\n",
        "        Labels.\n",
        "\n",
        "    subject : Tensor, shape = (n_samples,)\n",
        "        Identifiants des sujets.\n",
        "\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "    import os\n",
        "    import zipfile\n",
        "\n",
        "    # Download the dataset if necessary\n",
        "    if not os.path.isfile(os.path.join(\n",
        "        path, 'human+activity+recognition+using+smartphones.zip'\n",
        "    )):\n",
        "        from urllib.request import urlretrieve\n",
        "\n",
        "        if not os.path.exists(path):\n",
        "            os.makedirs(path)\n",
        "\n",
        "        url = (\n",
        "            'https://archive.ics.uci.edu/static/public/240/'\n",
        "            'human+activity+recognition+using+smartphones.zip'\n",
        "        )\n",
        "        urlretrieve(url, os.path.join(\n",
        "            path, 'human+activity+recognition+using+smartphones.zip'\n",
        "        ))\n",
        "\n",
        "    if not os.path.isfile(os.path.join(path, 'UCI HAR Dataset.zip')):\n",
        "        with zipfile.ZipFile(\n",
        "            os.path.join(path, 'human+activity+recognition+using+smartphones.zip'), 'r'\n",
        "        ) as zip_ref:\n",
        "            zip_ref.extractall(path)\n",
        "\n",
        "    if not os.path.isdir(os.path.join(path, 'UCI HAR Dataset')):\n",
        "        with zipfile.ZipFile(os.path.join(path, 'UCI HAR Dataset.zip'), 'r') as zip_ref:\n",
        "            zip_ref.extractall(path)\n",
        "\n",
        "    set_ = 'train' if train else 'test'\n",
        "    file_names = [\n",
        "            f'body_acc_x_{set_}.txt', f'body_acc_y_{set_}.txt', f'body_acc_z_{set_}.txt',\n",
        "            f'body_gyro_x_{set_}.txt', f'body_gyro_y_{set_}.txt', f'body_gyro_z_{set_}.txt',\n",
        "            f'total_acc_x_{set_}.txt', f'total_acc_y_{set_}.txt', f'total_acc_z_{set_}.txt',\n",
        "        ]\n",
        "\n",
        "    # Input data\n",
        "    X = np.asarray([\n",
        "        np.loadtxt(os.path.join(\n",
        "            path, 'UCI HAR Dataset', set_, 'Inertial Signals', file\n",
        "        )) for file in file_names\n",
        "    ])\n",
        "    X = np.transpose(X, (1, 0, 2))\n",
        "\n",
        "    # Output data\n",
        "    y = np.loadtxt(os.path.join(path, 'UCI HAR Dataset', set_, f'y_{set_}.txt'))\n",
        "\n",
        "    # Subjects\n",
        "    sujets = np.loadtxt(os.path.join(\n",
        "        path, 'UCI HAR Dataset', set_, f'subject_{set_}.txt'\n",
        "    ), dtype='int64')\n",
        "\n",
        "    # Convert to Tensors\n",
        "    X = torch.from_numpy(X).to(dtype=torch.float32)\n",
        "    y = torch.from_numpy(y - 1).to(dtype=torch.int64)\n",
        "    sujets = torch.from_numpy(sujets).to(dtype=torch.int64)\n",
        "\n",
        "    return X, y, sujets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOxe8IHNZcSE"
      },
      "source": [
        "Il suffit d'appeler cette fonction pour récupérer les jeux d'entraînement et de validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dc46hWEZcSF"
      },
      "outputs": [],
      "source": [
        "X_train, y_train, sujet_train = load_dataset(train=True)\n",
        "X_val, y_val, sujet_val = load_dataset(train=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyLnR5y9ZcSF"
      },
      "source": [
        "Pour chaque jeu de données, nous avons 3 variables :\n",
        "\n",
        "* `X` contient les entrées (c'est-à-dire les signaux) ; il s'agit d'un tenseur de taille `(n_observations, n_canaux, n_points)`.\n",
        "* `y` contient les sorties (c'est-à-dire les labels) ; il s'agit d'un tenseur de taille `(n_observations,)`.\n",
        "* `sujet` contient l'identification des sujets (car plusieurs activités ont été enregistrées pour chaque sujet) ; il s'agit d'un tenseur de taille `(n_observations,)`.\n",
        "\n",
        "Chaque observation est constituée de :\n",
        "* Entrée : 9 signaux (`n_canaux`) de longueur 128 (`n_points`).\n",
        "* Sortie : 1 label\n",
        "\n",
        "### Exercice 1\n",
        "\n",
        "Déterminez le nombre d'enregistrements dans les jeux d'entraînement et de validation.\n",
        "Déterminez (par du code) la taille de chaque observation (on admettra que toutes les observations ont la même taille, il suffit donc de calculer la taille d'une seule observation)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NASzE_hkZcSF"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xct7wkPmZcSF"
      },
      "source": [
        "La fonction `plot_sample()` définie ci-dessous permet d'afficher une observation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZ_vuH3dZcSG"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_sample(X, y, idx):\n",
        "    \"\"\"Plot the sample for the given index.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : array, shape = (n_samples, 9, 128)\n",
        "        Input samples.\n",
        "\n",
        "    y : array, shape = (n_samples)\n",
        "        Target samples.\n",
        "\n",
        "    idx : int\n",
        "        Index of the sample to plot.\n",
        "    \"\"\"\n",
        "    if not 0 <= idx < len(X):\n",
        "        raise ValueError(\"The index is not valid.\")\n",
        "\n",
        "    label_mapping = {\n",
        "        0: 'Walking',\n",
        "        1: 'Walking upstairs',\n",
        "        2: 'Walking downstairs',\n",
        "        3: 'Sitting',\n",
        "        4: 'Standing',\n",
        "        5: 'Laying'\n",
        "    }\n",
        "\n",
        "    labels = [\n",
        "        'Body acceleration - X',\n",
        "        'Body acceleration - Y',\n",
        "        'Body acceleration - Z',\n",
        "        'Body gyroscope - X',\n",
        "        'Body gyroscope - Y',\n",
        "        'Body gyroscope - Z',\n",
        "        'Total acceleration - X',\n",
        "        'Total acceleration - Y',\n",
        "        'Total acceleration - Z'\n",
        "    ]\n",
        "\n",
        "    for i, label in enumerate(labels):\n",
        "        plt.plot(X[idx, i], label=label)\n",
        "    plt.legend(bbox_to_anchor=(1., 1.))\n",
        "    _ = plt.title(label_mapping[y[idx].item()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0uIQi74ZcSG"
      },
      "source": [
        "### Exercice 2\n",
        "\n",
        "Affichez quelques observations des jeux d'entraînement et de validation à l'aide de la fonction `plot_sample()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5ccHI82ZcSG"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pp93ZCaEZcSG"
      },
      "source": [
        "### Exercice 3\n",
        "\n",
        "L'objectif de l'inférence est d'être capable d'identifier les activités de nouveaux sujets (c'est-à-dire de sujets qui ne sont pas présents dans le jeu d'entraînement).\n",
        "Vérifiez que l'intersection entre l'ensemble des sujets du jeu d'entraînement et celui des sujets du jeu de validation est vide.\n",
        "Pour ce faire, vous pouvez utiliser dans cet ordre :\n",
        "\n",
        "* la fonction [torch.unique()](https://pytorch.org/docs/stable/generated/torch.unique.html) qui renvoie les éléments uniques d'un tenseur,\n",
        "* la méthode [torch.Tensor.tolist()](https://pytorch.org/docs/stable/generated/torch.Tensor.tolist.html) qui transforme un tenseur en une liste,\n",
        "* la fonction native [set()](https://docs.python.org/fr/3/library/functions.html#func-set) pour créer un ensemble à partir d'une liste,\n",
        "* l'opérateur `&` qui effectue l'intersection entre deux ensembles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwYC5JaaZcSG"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCYz2dtHZcSH"
      },
      "source": [
        "### Exercice 4\n",
        "\n",
        "Calculez la distribution des classes sur les jeux d'entraînement et de validation.\n",
        "Vous pouvez utiliser la fonction [torch.bincount()](https://pytorch.org/docs/stable/generated/torch.bincount.html).\n",
        "Utilisez ces résultats pour proposer une métrique de classification pertinente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPeOV5bnZcSH"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_FLJlVoZcSH"
      },
      "source": [
        "**Réponse** : TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CAtqT5nZcSH"
      },
      "source": [
        "### Exercice 5\n",
        "\n",
        "Créez votre propre classe `CustomDataset()` héritant de la classe [torch.utils.data.Dataset()](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) pour définir votre jeu de données.\n",
        "Utilisez-là pour créer pour des *dataloaders* ([torch.utils.data.DataLoader()](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)) pour les jeux d'entraînement et de validation avec des lots de taille (`batch_size`) $32$.\n",
        "N'oubliez pas de mélanger (`suffle`) les observations pour le jeu d'entraînement, mais pas pour le jeu de validation.\n",
        "\n",
        "Vous pouvez vous inspirer du code utilisé pour le TP 1.2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2OvyUutPZcSH"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKf8ll2pZcSH"
      },
      "source": [
        "## Classe de base pour la classification\n",
        "\n",
        "Vous allez entraîner plusieurs modèles avec des architectures différentes.\n",
        "Néanmoins, plusieurs opérations seront identiques pour tous ces modèles.\n",
        "C'est pourquoi nous allons tout d'abord définir une classe de base avec toutes les opérations identiques.\n",
        "La classe `BaseClass()` définie ci-dessous va contenir ces opérations communes.\n",
        "\n",
        "### Exercice 6\n",
        "\n",
        "Complétez le code manquant dans les méthodes `__init__()`, `step()` et `configure_optimizers()` de la classe `BaseClass()` avec les informations suivantes :\n",
        "* `__init__()` : il faut définir la fonction de perte (`self.loss`) et les métriques pour les jeux d'entraînement (`self.metric_train`) et d'évaluation (`self.metric_val`);\n",
        "* `step()` : étant donné un lot d'observations (`batch`), il faut :\n",
        "    + récupérer les entrées (`X`) et les labels (`y`),\n",
        "    + calculer les logits pour ces entrées (`logits`),\n",
        "    + calculer la fonction de coût entre les logits et les labels (`loss`),\n",
        "    + calculer la classe prédite pour chacune des observations du lot (`y_pred`).\n",
        "* `configure_optimizers()` : on utilisera l'algorithme d'optimisation [torch.optim.Adam()](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html) avec les valeurs par défaut pour ses hyperparamètres."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFw2NllfZcSH"
      },
      "outputs": [],
      "source": [
        "import lightning as L\n",
        "\n",
        "\n",
        "class BaseClass(L.LightningModule):\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Constructeur.\n",
        "\n",
        "        Dans le constructeur, on exécute le constructeur de la clase mère et on définit\n",
        "        toutes les couches et fonctions d'activation de notre réseau de neurones.\n",
        "        \"\"\"\n",
        "        super().__init__()  # Toujours exécuter le constructeur de la classe mère\n",
        "\n",
        "        ### BEGIN TODO ###\n",
        "        # Initialisation de la fonction de perte\n",
        "        # self.loss =\n",
        "\n",
        "        # Initialisation des métriques\n",
        "        # self.metric_train =\n",
        "        # self.metric_val =\n",
        "        #### END TODO ####\n",
        "\n",
        "    def step(self, batch, dataset):\n",
        "        \"\"\"Effectue une étape.\n",
        "\n",
        "        Une étape consiste à passer d'un lot d'observations (l'argument batch)\n",
        "        à l'évaluation de la fonction de coût pour ce lot d'observations.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        batch : tuple\n",
        "            Un lot d'observations. Le premier élément du tuple est le lot\n",
        "            des entrées, le second est le lot des labels.\n",
        "\n",
        "        dataset : {\"training\", \"validation\"}\n",
        "            Jeu de données utilisé.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        loss : Tensor, shape = (1,)\n",
        "            La fonction de coût pour ce lot d'observations.\n",
        "        \"\"\"\n",
        "        ### BEGIN TODO ###\n",
        "        # X, y =\n",
        "        # logits =\n",
        "        # loss =\n",
        "        # y_pred =\n",
        "        #### END TODO ###\n",
        "\n",
        "        if dataset == \"training\":\n",
        "            metric = self.metric_train\n",
        "            name = \"train\"\n",
        "            bar_step = True\n",
        "        else:\n",
        "            metric = self.metric_val\n",
        "            name = \"val\"\n",
        "            bar_step = False\n",
        "\n",
        "        metric_score = metric(y_pred, y) # Évaluation de la métrique\n",
        "        self.log(f\"loss_{name}\", loss, prog_bar=bar_step, on_step=bar_step, on_epoch=True)\n",
        "        self.log(f\"metric_{name}\", metric_score, prog_bar=bar_step, on_step=bar_step, on_epoch=True)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def training_step(self, batch):\n",
        "        \"\"\"Effectue une étape d'entraînement.\"\"\"\n",
        "        return self.step(batch, \"training\")\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        \"\"\"Effectue une étape de validation.\"\"\"\n",
        "        return self.step(batch, \"validation\")\n",
        "\n",
        "    def on_train_start(self):\n",
        "        \"\"\"Code exécuté au début de l'entraînement.\"\"\"\n",
        "        string = f\"Version {self.trainer.logger.version}\"\n",
        "        print(f\"{string}\\n{'=' * len(string)}\\n\")\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        \"\"\"Code exécuté à la fin de chaque époque d'entraînement.\"\"\"\n",
        "        metrics = self.trainer.callback_metrics\n",
        "        string = (f\"\"\"\n",
        "            Époque {self.trainer.current_epoch + 1} / {self.trainer.max_epochs}\n",
        "            ------------------------------------------------\n",
        "            |     Jeu      | Fonction de perte | Précision |\n",
        "            | ------------ | ----------------- | --------- |\n",
        "            | Entraînement |{metrics['loss_train'].item():^19.5f}|{metrics['metric_train'].item():^11.3%}|\n",
        "            |  Validation  |{metrics['loss_val'].item():^19.5f}|{metrics['metric_val'].item():^11.3%}|\n",
        "            ------------------------------------------------\n",
        "        \"\"\")\n",
        "        string = '\\n'.join([line.strip() for line in string.split('\\n')])\n",
        "        print(string)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        \"\"\"Configure l'algorithme d'optimisation à utiliser.\"\"\"\n",
        "        ### BEGIN TODO ###\n",
        "        # optimizer =\n",
        "        #### END TODO ####\n",
        "        return optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEKaMucvZcSI"
      },
      "source": [
        "## Classification par perceptron multicouche\n",
        "\n",
        "Comme la longueur de chacun des signaux est fixe ($128$) après prétraitement des données, il est possible d'utiliser un perceptron multicouche.\n",
        "\n",
        "Vous allez implémenter un perceptron multicouche dans la classe `MLP()` définie ci-dessous avec l'architecture séquentielle suivante :\n",
        "\n",
        "* Aplatissement de l'observation pour la transformer en un tenseur à une dimension (un vecteur)\n",
        "* Couche linéaire avec 256 variables en sortie\n",
        "* Fonction d'action ReLU\n",
        "* Couche de désaction (*dropout*) avec une probabilité de $0.2$\n",
        "* Couche linéaire avec 64 variables en sortie\n",
        "* Fonction d'action ReLU\n",
        "* Couche linéaire avec 6 variables en sortie\n",
        "\n",
        "Voici les liens vers les documentations des classes pertinentes :\n",
        "[torch.nn.Flatten()](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html),\n",
        "[torch.nn.Linear()](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html),\n",
        "[torch.nn.ReLU()](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html) et\n",
        "[torch.nn.Dropout()](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html).\n",
        "\n",
        "### Exercice 7\n",
        "\n",
        "Complétez le code manquant dans les méthodes `__init__()` et `forward()` de la classe `MLP()`.\n",
        "Affichez un résumé de l'architecture. Combien de paramètres entraînables a-t-elle ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4YqvEihZcSI"
      },
      "outputs": [],
      "source": [
        "class MLP(BaseClass):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        ### BEGIN TODO ###\n",
        "\n",
        "        #### END TODO ####\n",
        "\n",
        "    def forward(self, x):\n",
        "        ### BEGIN TODO ###\n",
        "        # logits =\n",
        "        #### END TODO ####\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5ZhlYV1ZcSI"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xJ-8EM-ZcSJ"
      },
      "source": [
        "**Réponse** : TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGsTl5cDZcSJ"
      },
      "source": [
        "### Exercice 8\n",
        "\n",
        "Entraînez votre modèle pendant $10$ époques."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "AJyJ5_eyZcSJ"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Way-0L1nZcSJ"
      },
      "source": [
        "## Classification par réseau de neurones convolutif\n",
        "\n",
        "Comme la longueur de chacun des signaux est fixe ($128$) après prétraitement des données et que les données sont séquentielles, il est également possible et pertinent d'utiliser un réseau de neurones convolutif.\n",
        "\n",
        "Vous allez implémenter un réseau de neurones convolutif dans la classe `CNN()` définie ci-dessous avec l'architecture séquentielle suivante :\n",
        "\n",
        "* Couche de convolution unidimensionnelle avec $32$ canaux en sortie et un noyau de taille $9$\n",
        "* Fonction d'action ReLU\n",
        "* Couche de regroupement unidimensionnelle avec un noyau et un pas de taille $2$\n",
        "* Couche de convolution unidimensionnelle avec $64$ canaux en sortie et un noyau de taille $9$\n",
        "* Fonction d'action ReLU\n",
        "* Couche de regroupement unidimensionnelle avec un noyau et un pas de taille $2$\n",
        "* Aplatissement de l'entrée (en deux dimensions) pour la transformer en un tenseur à une dimension (un vecteur)\n",
        "* Couche linéaire avec $1664$ variables en entrée et $256$ variables en sortie\n",
        "* Fonction d'action ReLU\n",
        "* Couche linéaire avec $6$ variables en sortie\n",
        "\n",
        "Voici les liens vers les documentations des classes pertinentes :\n",
        "[torch.nn.Conv1d()](https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html),\n",
        "[torch.nn.ReLU()](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html),\n",
        "[torch.nn.MaxPool1d()](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool1d.html),\n",
        "[torch.nn.Flatten()](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html) et\n",
        "[torch.nn.Linear()](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html).\n",
        "\n",
        "### Exercice 9\n",
        "\n",
        "Complétez le code manquant dans les méthodes `__init__()` et `forward()` de la classe `CNN()`.\n",
        "Affichez un résumé de l'architecture. Combien de paramètres entraînables a-t-elle ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7kDzBYqZcSJ"
      },
      "outputs": [],
      "source": [
        "class CNN(BaseClass):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        ### BEGIN TODO ###\n",
        "\n",
        "        #### END TODO ####\n",
        "\n",
        "    def forward(self, x):\n",
        "        ### BEGIN TODO ###\n",
        "        # logits =\n",
        "        #### END TODO ####\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9ugN5EhZcSJ"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plMGg-QOZcSJ"
      },
      "source": [
        "**Réponse** : TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t55lJKT9ZcSJ"
      },
      "source": [
        "### Exercice 10\n",
        "\n",
        "Entraînez votre modèle pendant $10$ époques."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "X3CdUdmnZcSJ"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSQTpFDKZcSK"
      },
      "source": [
        "## Classification par réseau de neurones récurrent\n",
        "\n",
        "Comme les données sont séquentielles, il est également possible et pertinent d'utiliser un réseau de neurones récurrent.\n",
        "\n",
        "Vous allez implémenter un réseau de neurones récurrent dans la classe `RNN()` définie ci-dessous avec l'architecture séquentielle suivante :\n",
        "\n",
        "* Couche récurrente de type LSTM **bidirectionnelle** avec $256$ variables pour chaque état caché\n",
        "* Couche linéaire avec 6 variables en sortie\n",
        "\n",
        "Voici les liens vers les documentations des classes pertinentes :\n",
        "[torch.nn.LSTM()](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html) et\n",
        "[torch.nn.Linear()](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html).\n",
        "\n",
        "### Exercice 11\n",
        "\n",
        "Complétez le code manquant dans les méthodes `__init__()` et `forward()` de la classe `RNN()`.\n",
        "Affichez un résumé de l'architecture. Combien de paramètres entraînables a-t-elle ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Hzq8b2pZcSK"
      },
      "outputs": [],
      "source": [
        "class RNN(BaseClass):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        ### BEGIN TODO ###\n",
        "\n",
        "        #### END TODO ####\n",
        "\n",
        "    def forward(self, x):\n",
        "        ### BEGIN TODO ###\n",
        "        # logits =\n",
        "        #### END TODO ####\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9ZMK_1BZcSK"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nE8g837xZcSP"
      },
      "source": [
        "**Réponse** : TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OabWV1AZcSP"
      },
      "source": [
        "### Exercice 12\n",
        "\n",
        "Entraînez votre modèle pendant $10$ époques."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "ZTRt1UEmZcSP"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6liagAbZcSP"
      },
      "source": [
        "### Exercice 13\n",
        "\n",
        "Finalement, lequel de vos trois modèles est le meilleur ? Justifiez votre réponse."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqprfhw3ZcSQ"
      },
      "source": [
        "**Réponse** : TODO"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Format de la Cellule Texte Brut",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}